{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "forms = set() #We'll store the derivational forms in a set to eliminate duplicates\n",
    "for happy_lemma in wn.lemmas(\"\"): #for each \"happy\" lemma in WordNet\n",
    "    forms.add(happy_lemma.name()) #add the lemma itself\n",
    "    for related_lemma in happy_lemma.derivationally_related_forms(): #for each related lemma\n",
    "        forms.add(related_lemma.name()\n",
    "        \n",
    "print(forms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "\n",
    "class nGraph():\n",
    "    def __init__(self, uri, user, password):\n",
    "        self._driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "    def close(self):\n",
    "        self._driver.close()\n",
    "    \n",
    "\n",
    "    def __run_statement(self, query):\n",
    "        with self._driver.session() as session:\n",
    "            return session.write_transaction(self.run, query)\n",
    "\n",
    "    def run_raw_query(self, query):\n",
    "        return self.__run_statement(query)\n",
    "\n",
    "    def get_label(self, entity):\n",
    "        query = \"MATCH (n:ObjectEntity{objectEntity:'\"+entity+\"'}) RETURN labels(n) as lb\"\n",
    "        r = self.__run_statement(query)[1].records()\n",
    "        for n in r:\n",
    "            return n['lb']\n",
    "\n",
    "    def check_node_exist(self, node_entity):\n",
    "        cypher_s = \"MATCH (n:ObjectEntity{objectEntity:'\"+node_entity+\"'}) RETURN count(n) <> 0 as res\"\n",
    "        r = self.__run_statement(cypher_s)[1].records()\n",
    "        for n in r:\n",
    "            return n['res']\n",
    "    \n",
    "    def get_direct_meaning_node(self, entity, r_type):\n",
    "        query = \"MATCH(n:ObjectEntity{objectEntity:'\"+entity+\"'})-[r:\"+r_type+\"]-(v:ROOTNODE) return v.objectEntity as root\"\n",
    "        r = self.__run_statement(query)[1].records()\n",
    "        for n in r:\n",
    "            return n['root']\n",
    "\n",
    "    \n",
    "\n",
    "    def check_no_direct_vn_meaning(self, node_entity):\n",
    "        cypher_s = \"match(n:ObjectEntity{objectEntity:'\"+node_entity+\"'})-[r:TRANS_EN_VI]-() return count(r) = 0 as res\"\n",
    "        r = self.__run_statement(cypher_s)[1].records()\n",
    "        for n in r:\n",
    "            return n['res']\n",
    "\n",
    "    def get_meaning_of_word(self, w, pos):\n",
    "        query = \"match (n:ObjectEntity{objectEntity:'\"+w+\"'})-[r:TRANS_EN_VI|:EXPLAINAION_VI_VI]->(v\"+pos+\")  return n,r,v\"\n",
    "        return self.__run_statement(query)\n",
    "    def get_meaning_itself(self, w):\n",
    "        query = \"match (n:ObjectEntity{objectEntity:'\"+w+\"'})-[:LANG_POLY_MEANING]->(v) where exists(v.definition)  return labels(v) as lbs, v.definition as def ,ID(v) as id\"\n",
    "        return self.__run_statement(query)\n",
    "    def get_en_synonynm(self, _id):\n",
    "        query = 'match (n)-[:LANG_RELATED_SYNONYM]->(v) where id(n)='+str(_id) + \" return v.objectEntity as s\"\n",
    "        return self.__run_statement(query)\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        cypher_s = \"MATCH (n {name: '\"+key+\"'}) return n\" \n",
    "        return self.__run_statement(cypher_s)\n",
    "    \n",
    "    @staticmethod\n",
    "    def run(tx, message):\n",
    "        result = tx.run(message)\n",
    "        avail = result.summary().result_available_after\n",
    "        cons = result.summary().result_consumed_after\n",
    "        total_time = avail + cons\n",
    "        return str(total_time)+\" ms\", result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "e_words= [\"abolitionizing\"]\n",
    "ps =PorterStemmer()\n",
    "for w in e_words:\n",
    "    rootWord=ps.stem(w)\n",
    "    print(rootWord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, pos_tag\n",
    "text = word_tokenize(\"browner\")\n",
    "pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "g = nGraph(\"bolt://localhost:7687\", \"ajax997\", \"lumia1020\")\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = g.run_raw_query(\"match (n:ROOTNODE)-[:LANG_GRAMMAR_GERUND]->(v:GERUND) where not (n)-[:LANG_POS_MEANING]-(v) return v.objectEntity as r, labels(v) as lb\")[1].records()\n",
    "for e in results:\n",
    "    if pos_tag([e['r']])[0][1] == \"VBG\" and \"'\" not in e['r']:\n",
    "        g.run_raw_query(\"match (n:GERUND{objectEntity:'\"+e['r']+\"'})-[:LANG_GRAMMAR_GERUND]-(v:ROOTNODE) where not (n)-[:LANG_POS_MEANING]-(v) set n:VBG create (n)-[:LANG_POS_MEANING]->(v)\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "from pattern.en import pluralize, singularize\n",
    "\n",
    "results = g.run_raw_query(\"match (n:ROOTNODE:ObjectEntity)-[:LANG_POLY_MEANING]->(v:NOUN) where not (n)<-[:LANG_POS_MEANING]-(:NNS) and apoc.text.indexOf(n.objectEntity,' ') = -1 and not n:NNS return n.objectEntity as r\")[1].records()\n",
    "\n",
    "for x in results:\n",
    "    ori = x['r']\n",
    "    pr = pluralize(ori).replace(\"'\", \"\\'\")\n",
    "    if pr[len(pr)-2:] != 'ss':\n",
    "        \n",
    "            \n",
    "        g.run_raw_query(\"merge (n:NNS{objectEntity:\\\"\"+pr+\"\\\", language:'english'}) merge (v:ROOTNODE:ObjectEntity{objectEntity:\\\"\"+ori+\"\\\"}) merge (n)-[:LANG_POS_MEANING]->(v)\")\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "penes\n"
    }
   ],
   "source": [
    "from pattern.en import pluralize, singularize\n",
    "print( pluralize('')) #children\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pattern.en import comparative, superlative\n",
    "superlative('damp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Failed to read from defunct connection Address(host='localhost', port=7687) (Address(host='::1', port=7687, flow_info=0, scope_id=0))\nTransaction failed and will be retried in 1.0809586701801874s (Failed to write to closed connection Address(host='localhost', port=7687) (Address(host='::1', port=7687, flow_info=0, scope_id=0)))\n"
    }
   ],
   "source": [
    "results = g.run_raw_query(\"match (n:ROOTNODE) where not (n)<--(:NNS) and (n)-[:LANG_POLY_MEANING]->(:NOUN) and apoc.text.indexOf(n.objectEntity, ' ')= -1 and right(n.objectEntity, 1)<> 's' return n.objectEntity as r\")[1].records()\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0\n"
    }
   ],
   "source": [
    "c = 0\n",
    "for r in results:\n",
    "    su = pluralize(r['r'])\n",
    "    \n",
    "    g.run_raw_query(\"merge (a:ObjectEntity:ROOTNODE{objectEntity:\\\"\"+r['r']+\"\\\"}) merge (b:ObjectEntity:ROOTNODE{objectEntity:\\\"\"+su+\"\\\"}) merge(a)<-[:LANG_POS_MEANING]-(b) set b:NNS\")\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autocorrect import Speller\n",
    "spell = Speller(lang='en')\n",
    "spell(\"sentime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "literals = \"zxcvbnmasdfghjklqpwoeiruty1234567890\"\n",
    "for x in literals:\n",
    "    g.run_raw_query(\"create (n:Literal{l:'\"+x+\"'})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"match (l1:Literal{l:'k'}), (l1:Literal{l:'i'}), (l1:Literal{l:'s'}),(l1:Literal{l:'o'}),(l1:Literal{l:'q'}), (v:Root) where (l1)-[r1:PREDICT]->(v) or (l2)-[r2:PREDICT]->(v) or (l3)-[r3:PREDICT]->(v) or (l4)-[r4:PREDICT]->(v) or (l5)-[r5:PREDICT]->(v) with count(r1) + count(r2) + count(r3) + count(r4) + count(r5) as num retrun n orderby num limti 5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"optional match (l1:Literal{l:'s'})-[r1:PREDICT]->(v:Root) optional match (l2:Literal{l:'c'})-[r2:PREDICT]->(v:Root) optional match (l3:Literal{l:'a'})-[r3:PREDICT]->(v:Root) optional match(l4:Literal{l:'g'})-[r4:PREDICT]->(v:Root) optional match(l5:Literal{l:'l'})-[r5:PREDICT]->(v:Root) return v, count(r1) + count(r2) + count(r3) + count(r4) + count(r5) as value ORDER BY value DESC limit 10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"antisematism\"\n",
    "query = \"\"\n",
    "return_s = \"\"\n",
    "for i in range(0, len(word)):\n",
    "    return_s += (\"+ count(l\"+str(i)+\")\")\n",
    "    query += \"optional match (l1:Literal{l:'\"+word[i]+\"'})-[r\"+str(i)+\":PREDICT]->(v:Root) \"\n",
    "\n",
    "print(query +\"return \" + return_s[1:] + \" as value ORDER BY value DESC limit 10\")\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [\"furrier\",\n",
    "\"flipper\",\n",
    "\"advancer\",\n",
    "\"salter\",\n",
    "\"insider\",\n",
    "\"fiver\",\n",
    "\"fuller\",\n",
    "\"jointer\",\n",
    "\"thinner\",\n",
    "\"damper\",\n",
    "\"ranker\",\n",
    "\"matter\",\n",
    "\"halter\",\n",
    "\"feller\",\n",
    "\"goer\",\n",
    "\"fancier\",\n",
    "\"haler\",\n",
    "\"graver\",\n",
    "\"faker\",\n",
    "\"homer\",\n",
    "\"number\",\n",
    "\"goner\",\n",
    "\"diviner\",\n",
    "\"dimmer\",\n",
    "\"trimmer\",\n",
    "\"liter\",\n",
    "\"closer\",\n",
    "\"cracker\",\n",
    "\"cutter\",\n",
    "\"first-rater\",\n",
    "\"cleaner\",\n",
    "\"flyer\",\n",
    "\"freelancer\",\n",
    "\"worse\",\n",
    "\"fitter\",\n",
    "\"rusher\",\n",
    "\"cooler\",\n",
    "\"diffuser\",\n",
    "\"broker\",\n",
    "\"flasher\",\n",
    "\"wilder\",\n",
    "\"welcomer\",\n",
    "\"layer\",\n",
    "\"wetter\",\n",
    "\"mummer\",\n",
    "\"part-timer\",\n",
    "\"paster\",\n",
    "\"owner\",\n",
    "\"trigger\",\n",
    "\"puffer\",\n",
    "\"petter\",\n",
    "\"welsher\",\n",
    "\"rainier\",\n",
    "\"wester\",\n",
    "\"patter\",\n",
    "\"rasher\",\n",
    "\"passer\",\n",
    "\"mocker\",\n",
    "\"primer\",\n",
    "\"meeter\",\n",
    "\"minter\",\n",
    "\"bluffer\",\n",
    "\"bother\",\n",
    "\"prompter\",\n",
    "\"oliver\",\n",
    "\"old-timer\",\n",
    "\"bounder\",\n",
    "\"popper\",\n",
    "\"porter\",\n",
    "\"norther\",\n",
    "\"bragger\",\n",
    "\"boner\",\n",
    "\"offer\",\n",
    "\"blinder\",\n",
    "\"planer\",\n",
    "\"muster\",\n",
    "\"beater\",\n",
    "\"dryer\",\n",
    "\"fresher\",\n",
    "\"better\",\n",
    "\"camper\",\n",
    "\"founder\",\n",
    "\"loner\",\n",
    "\"easter\",\n",
    "\"limper\",\n",
    "\"buffer\",\n",
    "\"leer\",\n",
    "\"downer\",\n",
    "\"mainer\",\n",
    "\"archer\",\n",
    "\"bustier\",\n",
    "\"buster\",\n",
    "\"balder\",\n",
    "\"backer\",\n",
    "\"liver\",\n",
    "\"bummer\",\n",
    "\"mariner\",\n",
    "\"litter\",\n",
    "\"outsider\",\n",
    "\"lower\",\n",
    "\"idler\",\n",
    "\"longer\",\n",
    "\"bayer\",\n",
    "\"plumber\",\n",
    "\"madder\",\n",
    "\"loather\",\n",
    "\"lighter\",\n",
    "\"leaner\",\n",
    "\"dresser\",\n",
    "\"doubler\",\n",
    "\"butcher\",\n",
    "\"squinter\",\n",
    "\"shammer\",\n",
    "\"stapler\",\n",
    "\"solder\",\n",
    "\"skewer\",\n",
    "\"strayer\",\n",
    "\"voider\",\n",
    "\"tangier\",\n",
    "\"roaster\",\n",
    "\"stranger\",\n",
    "\"serer\",\n",
    "\"waster\",\n",
    "\"splitter\",\n",
    "\"rounder\",\n",
    "\"tenner\",\n",
    "\"signer\",\n",
    "\"sneaker\",\n",
    "\"shutter\",\n",
    "\"stretcher\",\n",
    "\"souther\",\n",
    "\"tamer\",\n",
    "\"third-rater\",\n",
    "\"spreader\",\n",
    "\"swaggerer\",\n",
    "\"teenager\",\n",
    "\"smoother\",\n",
    "\"rummer\",\n",
    "\"skimmer\",\n",
    "\"topper\",\n",
    "\"slacker\",\n",
    "\"scrubber\",\n",
    "\"tanner\",\n",
    "\"utterer\",\n",
    "\"stocker\",\n",
    "\"setter\",\n",
    "\"securer\",\n",
    "\"steeper\",\n",
    "\"snuffer\",\n",
    "\"sharper\",\n",
    "\"slicker\",\n",
    "\"sparer\",\n",
    "\"sounder\",\n",
    "\"warmer\",\n",
    "\"stoner\"]\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in x:\n",
    "    g.run_raw_query(\"match (n:ROOTNODE{objectEntity:'\"+i+\"'})-[r:LANG_POS_MEANING]-(v:NNS) delete r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}