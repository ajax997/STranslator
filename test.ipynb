{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "forms = set() #We'll store the derivational forms in a set to eliminate duplicates\n",
    "for happy_lemma in wn.lemmas(\"\"): #for each \"happy\" lemma in WordNet\n",
    "    forms.add(happy_lemma.name()) #add the lemma itself\n",
    "    for related_lemma in happy_lemma.derivationally_related_forms(): #for each related lemma\n",
    "        forms.add(related_lemma.name()\n",
    "        \n",
    "print(forms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "\n",
    "class nGraph():\n",
    "    def __init__(self, uri, user, password):\n",
    "        self._driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "    def close(self):\n",
    "        self._driver.close()\n",
    "    \n",
    "\n",
    "    def __run_statement(self, query):\n",
    "        with self._driver.session() as session:\n",
    "            return session.write_transaction(self.run, query)\n",
    "\n",
    "    def run_raw_query(self, query):\n",
    "        return self.__run_statement(query)\n",
    "\n",
    "    def get_label(self, entity):\n",
    "        query = \"MATCH (n:ObjectEntity{objectEntity:'\"+entity+\"'}) RETURN labels(n) as lb\"\n",
    "        r = self.__run_statement(query)[1].records()\n",
    "        for n in r:\n",
    "            return n['lb']\n",
    "\n",
    "    def check_node_exist(self, node_entity):\n",
    "        cypher_s = \"MATCH (n:ObjectEntity{objectEntity:'\"+node_entity+\"'}) RETURN count(n) <> 0 as res\"\n",
    "        r = self.__run_statement(cypher_s)[1].records()\n",
    "        for n in r:\n",
    "            return n['res']\n",
    "    \n",
    "    def get_direct_meaning_node(self, entity, r_type):\n",
    "        query = \"MATCH(n:ObjectEntity{objectEntity:'\"+entity+\"'})-[r:\"+r_type+\"]-(v:ROOTNODE) return v.objectEntity as root\"\n",
    "        r = self.__run_statement(query)[1].records()\n",
    "        for n in r:\n",
    "            return n['root']\n",
    "\n",
    "    \n",
    "\n",
    "    def check_no_direct_vn_meaning(self, node_entity):\n",
    "        cypher_s = \"match(n:ObjectEntity{objectEntity:'\"+node_entity+\"'})-[r:TRANS_EN_VI]-() return count(r) = 0 as res\"\n",
    "        r = self.__run_statement(cypher_s)[1].records()\n",
    "        for n in r:\n",
    "            return n['res']\n",
    "\n",
    "    def get_meaning_of_word(self, w, pos):\n",
    "        query = \"match (n:ObjectEntity{objectEntity:'\"+w+\"'})-[r:TRANS_EN_VI|:EXPLAINAION_VI_VI]->(v\"+pos+\")  return n,r,v\"\n",
    "        return self.__run_statement(query)\n",
    "    def get_meaning_itself(self, w):\n",
    "        query = \"match (n:ObjectEntity{objectEntity:'\"+w+\"'})-[:LANG_POLY_MEANING]->(v) where exists(v.definition)  return labels(v) as lbs, v.definition as def ,ID(v) as id\"\n",
    "        return self.__run_statement(query)\n",
    "    def get_en_synonynm(self, _id):\n",
    "        query = 'match (n)-[:LANG_RELATED_SYNONYM]->(v) where id(n)='+str(_id) + \" return v.objectEntity as s\"\n",
    "        return self.__run_statement(query)\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        cypher_s = \"MATCH (n {name: '\"+key+\"'}) return n\" \n",
    "        return self.__run_statement(cypher_s)\n",
    "    \n",
    "    @staticmethod\n",
    "    def run(tx, message):\n",
    "        result = tx.run(message)\n",
    "        avail = result.summary().result_available_after\n",
    "        cons = result.summary().result_consumed_after\n",
    "        total_time = avail + cons\n",
    "        return str(total_time)+\" ms\", result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "e_words= [\"abolitionizing\"]\n",
    "ps =PorterStemmer()\n",
    "for w in e_words:\n",
    "    rootWord=ps.stem(w)\n",
    "    print(rootWord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('browner', 'NN')]"
     },
     "metadata": {},
     "execution_count": 85
    }
   ],
   "source": [
    "from nltk import word_tokenize, pos_tag\n",
    "text = word_tokenize(\"browner\")\n",
    "pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "g = nGraph(\"bolt://localhost:7687\", \"ajax997\", \"lumia1020\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = g.run_raw_query(\"match (n:ROOTNODE)-[:LANG_GRAMMAR_GERUND]->(v:GERUND) where not (n)-[:LANG_POS_MEANING]-(v) return v.objectEntity as r, labels(v) as lb\")[1].records()\n",
    "for e in results:\n",
    "    if pos_tag([e['r']])[0][1] == \"VBG\" and \"'\" not in e['r']:\n",
    "        g.run_raw_query(\"match (n:GERUND{objectEntity:'\"+e['r']+\"'})-[:LANG_GRAMMAR_GERUND]-(v:ROOTNODE) where not (n)-[:LANG_POS_MEANING]-(v) set n:VBG create (n)-[:LANG_POS_MEANING]->(v)\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "from pattern.en import pluralize, singularize\n",
    "\n",
    "results = g.run_raw_query(\"match (n:ROOTNODE:ObjectEntity)-[:LANG_POLY_MEANING]->(v:NOUN) where not (n)<-[:LANG_POS_MEANING]-(:NNS) and apoc.text.indexOf(n.objectEntity,' ') = -1 and not n:NNS return n.objectEntity as r\")[1].records()\n",
    "\n",
    "for x in results:\n",
    "    ori = x['r']\n",
    "    pr = pluralize(ori).replace(\"'\", \"\\'\")\n",
    "    if pr[len(pr)-2:] != 'ss':\n",
    "        \n",
    "            \n",
    "        g.run_raw_query(\"merge (n:NNS{objectEntity:\\\"\"+pr+\"\\\", language:'english'}) merge (v:ROOTNODE:ObjectEntity{objectEntity:\\\"\"+ori+\"\\\"}) merge (n)-[:LANG_POS_MEANING]->(v)\")\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pattern.en import pluralize, singularize\n",
    "print( pluralize('tenderfoot')) #children\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'dampest'"
     },
     "metadata": {},
     "execution_count": 97
    }
   ],
   "source": [
    "from pattern.en import comparative, superlative\n",
    "superlative('damp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = g.run_raw_query(\"match (n:ObjectEntity)-[:LANG_POLY_MEANING]->(:ADJECTIVE) where right(n.objectEntity, 2) <> 'ed' and right(n.objectEntity, 3) <> 'ing' return DISTINCT n.objectEntity as r\")[1].records()\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "2338\n"
    }
   ],
   "source": [
    "c = 0\n",
    "for r in results:\n",
    "    su = superlative(r['r'])\n",
    "    cp = comparative(r['r'])\n",
    "    if not su.startswith(\"most\"):\n",
    "        c+=1\n",
    "        g.run_raw_query(\"merge (a:ObjectEntity:ROOTNODE{objectEntity:\\\"\"+r['r']+\"\\\"}) merge (b:ObjectEntity:ROOTNODE{objectEntity:\\\"\"+cp+\"\\\"}) merge (c:ObjectEntity:ROOTNODE{objectEntity:\\\"\"+su+\"\\\"}) set b:JJR, c:JJS merge (c)-[:LANG_POS_MEANING]->(a) merge(b)-[:LANG_POS_MEANING]->(a)\")\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'septime'"
     },
     "metadata": {},
     "execution_count": 123
    }
   ],
   "source": [
    "from autocorrect import Speller\n",
    "spell = Speller(lang='en')\n",
    "spell(\"sentime\")"
   ]
  }
 ]
}